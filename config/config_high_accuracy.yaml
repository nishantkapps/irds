# High Accuracy Configuration (Target: 90%+)
# More data, longer training, smaller learning rate

data:
  folder_path: "../data"
  max_files: 300                    # More data for better accuracy
  sequence_length: 20               # Longer sequences for better context
  test_size: 0.15                   # Smaller test set for more training data
  random_state: 42

model:
  skeleton_encoder:
    hidden_dim: 512                 # Larger hidden dimension
    num_layers: 3                  # More layers
    dropout: 0.3                   # More dropout for regularization
    attention_heads: 16            # More attention heads
    
  text_encoder:
    embedding_dim: 256             # Larger text embedding
    hidden_dim: 512                # Larger text encoder
    num_layers: 3                  # More layers
    
  clip_model:
    embedding_dim: 512             # Larger final embedding
    logit_scale: 0.05              # Lower temperature

training:
  num_epochs: 150                  # More epochs
  batch_size: 8                    # Smaller batch size for better learning
  learning_rate: 0.0001           # Lower learning rate for stability
  
  optimizer: "AdamW"
  weight_decay: 0.01
  beta1: 0.9
  beta2: 0.999
  eps: 1e-8
  
  lr_scheduler: "CosineAnnealingLR"
  lr_warmup_epochs: 20
  lr_min: 0.000001
  
  contrastive_weight: 0.6
  classification_weight: 0.4
  temperature: 0.05

augmentation:
  enabled: true
  noise_std: 0.005
  rotation_angle: 3
  time_shift: 0.05
  scale_factor: 0.05

regularization:
  dropout: 0.3
  weight_decay: 0.01
  gradient_clip: 0.5
  early_stopping:
    enabled: true
    patience: 30
    min_delta: 0.0005

output:
  model_save_path: "outputs/clip_gesture_model_high_acc.pth"
  scaler_save_path: "outputs/clip_gesture_scaler_high_acc.pkl"
  info_save_path: "outputs/clip_gesture_info_high_acc.json"
  plots_save_path: "outputs/clip_training_curves_high_acc.png"
  confusion_matrix_path: "outputs/clip_confusion_matrix_high_acc.png"

experiment:
  name: "clip_gesture_high_accuracy"
  tags: ["clip", "gesture", "high_accuracy", "rocm"]
  notes: "High accuracy CLIP gesture recognition targeting 90%+"
